{
 "metadata": {
  "name": "",
  "signature": "sha256:8c7c2fe94c4fa38095ffa7856448cf16d416133a459a63be3b0dbd883e0f10c4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import bs4\n",
      "import requests\n",
      "import re\n",
      "import json\n",
      "import os\n",
      "#from datetime import timedelta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resp = requests.get('http://www.dotabuff.com/matches/1154125699')\n",
      "soup = bs4.BeautifulSoup(resp.text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stat_fix = re.compile('[k]')\n",
      "dig_fix = re.compile('(\\d)')\n",
      "match_id_parse = re.compile('\\d+')\n",
      "match_href = re.compile('^\\/matches\\/')\n",
      "pick_ban = re.compile('(ban|pick)')\n",
      "hero_finder = re.compile('\\/heroes\\/\\w+')\n",
      "faction_find = re.compile('faction\\-')\n",
      "\n",
      "stat_col_names = ['Team','Hero','Player','Level','Kills','Deaths','Assists','Gold','Last_Hits','Denies','XPM','GPM','Hero_Dmg','Hero_Healed','Tower_Damage','Item_1','Item_2','Item_3','Item_4','Item_5','Item_6']\n",
      "ability_col_names = ['Hero'] + ['Level_%d' % x for x in range(1,26)]\n",
      "details_col_names = ['Tournment','Mode','Region','Duration']\n",
      "sub_pages = ['','builds','kills','farm','objectives','runes','vision','chat','log']\n",
      "sides = ['radiant','dire']\n",
      "\n",
      "def get_match_id(soup):\n",
      "    match_id = int(match_id_parse.findall(soup.find('div',{'class':'content-header-title'}).text)[0])\n",
      "    return match_id\n",
      "\n",
      "def parse_match_section(sec):\n",
      "    title = sec.find('header').text\n",
      "    # Match table\n",
      "    sec_stats = []\n",
      "    for tr in sec.find('table').find_all('tr')[1:6]:\n",
      "        tds = tr.find_all('td')\n",
      "        hero = tds[0].find('img')['title']\n",
      "        player = tds[1].text\n",
      "        stats = [int(''.join(dig_fix.findall(stat_fix.sub('00',tds[i].text)))) for i in range(3,15)]\n",
      "        items = [x['alt'] for x in tds[15].find_all('img')]\n",
      "        if len(items) < 6:\n",
      "            items = items + ['none']*(6-len(items))\n",
      "        parsed_row = [hero] + [player] + stats + items\n",
      "        sec_stats = np.append(sec_stats,np.array(parsed_row))\n",
      "    team_stats = np.array([title]*5).reshape((5,1))\n",
      "    team_stats = np.hstack((team_stats,np.reshape(sec_stats,(5,20))))\n",
      "    return team_stats\n",
      "\n",
      "def parse_game_stats(soup):\n",
      "    match_id = get_match_id(soup)\n",
      "    teams = np.array(['radiant']*5 + ['dire']*5)\n",
      "    team_stats = []\n",
      "    for side in sides:\n",
      "        sec = soup.find('section',{'class':side})\n",
      "        team_stats = np.append(team_stats, parse_match_section(sec))\n",
      "    team_stats = np.reshape(team_stats, (10,21))\n",
      "    df = pd.DataFrame(team_stats, columns = stat_col_names)\n",
      "    df['Side'] = teams\n",
      "    df['match_id'] = match_id\n",
      "    return df\n",
      "\n",
      "def parse_diff_xp(soup):\n",
      "    match_id = get_match_id(soup)\n",
      "    plot_json = json.loads(soup.find('div',{'data-flot':'chart-value-minute'})['data-json'])\n",
      "    df = pd.DataFrame(plot_json[1]['data'], columns = ['time','xp'])\n",
      "    df['match_id'] = match_id\n",
      "    return df\n",
      "\n",
      "def parse_chart(soup):\n",
      "    plot_json = json.loads(soup['data-json'])\n",
      "    df = pd.DataFrame(plot_json[1]['data'], columns = ['time','value'])\n",
      "    return df\n",
      "\n",
      "def parse_hero_chart(soup):\n",
      "    df = pd.DataFrame()\n",
      "    for s in json.loads(soup['data-json']):\n",
      "        hero = s['label']\n",
      "        ts = s['data']\n",
      "        df_hero = pd.DataFrame(ts)\n",
      "        df_hero.columns = ['time','value']\n",
      "        df_hero['hero'] = hero\n",
      "        df = df.append(df_hero)\n",
      "    return df[['time','hero','value']]\n",
      "\n",
      "def parse_diff_gold(soup):\n",
      "    match_id = get_match_id(soup)\n",
      "    plot_json = json.loads(soup.find('div',{'data-flot':'chart-value-minute'})['data-json'])\n",
      "    df = pd.DataFrame(plot_json[1]['data'], columns = ['time','gold'])\n",
      "    df['match_id'] = match_id\n",
      "    return df\n",
      "\n",
      "def parse_ability_builds(soup):\n",
      "    match_id = get_match_id(soup)\n",
      "    ability_arr = []\n",
      "    for team in soup.find_all('article',{'class':'ability-builds'}):\n",
      "        for tr in team.find_all('tr')[1::]:\n",
      "            skill_arr = []\n",
      "            for td in tr.find_all('td'):\n",
      "                if td.find('img') is not None:\n",
      "                    skill_arr.append(td.find('img')['alt'])\n",
      "                else:\n",
      "                    skill_arr.append('none')\n",
      "            ability_arr = ability_arr + skill_arr\n",
      "    ability_arr = np.reshape(ability_arr, (10,26))\n",
      "    df = pd.DataFrame(ability_arr, columns = ability_col_names)\n",
      "    df['match_id'] = match_id\n",
      "    return df\n",
      "\n",
      "def get_match_details(soup):\n",
      "    match_id = get_match_id(soup)\n",
      "    dds = soup.find('div',{'id':'content-header-secondary'}).find_all('dd')\n",
      "    details = [x.text for x in dds[:-1]]\n",
      "    details[-1] = duration_to_sec(details[-1])\n",
      "    time_stamp = pd.to_datetime(dds[-1].find('time')['datetime'])\n",
      "    match_details = np.append(match_id, details)\n",
      "    match_details = np.append(match_details, time_stamp)\n",
      "    match_details[0] = int(match_details[0])\n",
      "    return match_details\n",
      "    \n",
      "def duration_to_sec(dur_str):\n",
      "    if ':' not in dur_str:\n",
      "        return 0\n",
      "    vals = [int(x) for x in dur_str.split(':')]\n",
      "    if vals[0] < 0:\n",
      "        return vals[0]*60 - vals[1]\n",
      "    else:\n",
      "        return vals[0]*60 + vals[1]\n",
      "\n",
      "def get_match_ids(soup):\n",
      "    return [int(x.text) for x in match_soup.find_all('a', href = match_href, text = match_id_parse)]\n",
      "\n",
      "def pull_all_match_pages(ids):\n",
      "    for m_id in ids:\n",
      "        base_url = 'http://www.dotabuff.com/matches/%d' % m_id\n",
      "        for page in sub_pages:\n",
      "            fetch_url = base_url + '/' + page\n",
      "            fName = os.path.join('D:/dota2_matches/%s/' % page, '%d_%s.txt' % (m_id,page))\n",
      "            with open(fName, 'wb') as txt_file:\n",
      "                txt_file.write(requests.get(fetch_url).text.encode('UTF-8'))   \n",
      "                \n",
      "def get_picks_and_bans(soup):\n",
      "    match_id = get_match_id(soup)\n",
      "    pb = soup.findAll('div',{'class':pick_ban})\n",
      "    pb_phase = []\n",
      "    for hero in pb[1::]:\n",
      "        sel = hero['class'][0]\n",
      "        name = hero.find('img')['alt']\n",
      "        seq = int(hero.find('div',{'class':'seq'}).text)\n",
      "        pb_phase = pb_phase + [seq,sel,name]\n",
      "    df = pd.DataFrame(np.reshape(pb_phase, (-1,3)), columns = ['sequence', 'action','hero'])\n",
      "    df = df[df.action != 'picks-inline']\n",
      "    df['sequence'] = df.sequence.astype(int)\n",
      "    df['match_id'] = match_id\n",
      "    return df.sort('sequence').reset_index(drop = True)\n",
      "\n",
      "def parse_item_sequence(soup):\n",
      "    match_id = get_match_id(soup)\n",
      "    players = soup.findAll('section',{'class':'performance-artifact'})\n",
      "    item_builds = pd.DataFrame()\n",
      "    for player in players:\n",
      "        hero = player.find('a', {'href':hero_finder}).find('img')['alt']\n",
      "        for buy in player.findAll('div',{'class':'segment expanded'}):\n",
      "            time_stamp = duration_to_sec(buy.find('div',{'class':'time'}).text)\n",
      "            items = [x['alt'] for x in buy.findAll('img')]\n",
      "            df_user = pd.DataFrame(items)\n",
      "            df_user['time_stamp'] = time_stamp\n",
      "            df_user['hero'] = hero\n",
      "            item_builds = item_builds.append(df_user)\n",
      "    #df = pd.DataFrame(item_builds)\n",
      "    #df['match_id'] = match_id\n",
      "    item_builds.columns = ['item','time_stamp','hero']\n",
      "    item_builds['match_id'] = match_id\n",
      "    return item_builds[['match_id','time_stamp','hero','item']].sort(['hero','time_stamp']).reset_index(drop=True)\n",
      "\n",
      "def parse_farm_charts(soup):\n",
      "    match_id = get_match_id(soup)\n",
      "    charts = soup.findAll('div',{'data-flot':'chart-value-minute'})\n",
      "    df_xp = parse_chart(charts[0])\n",
      "    df_xp.columns = ['time','team_xp']\n",
      "    df_gold = parse_chart(charts[1])\n",
      "    df_gold.columns = ['time','team_gold']\n",
      "    df_last_hits = parse_hero_chart(charts[2])\n",
      "    df_last_hits.columns = ['time','hero','last_hits']\n",
      "    df_hero_gold = parse_hero_chart(charts[3])\n",
      "    df_hero_gold.columns = ['time','hero','gold']\n",
      "    df_team = df_xp.merge(df_gold)\n",
      "    df_hero = df_last_hits.merge(df_hero_gold)\n",
      "    df_team['match_id'] = match_id\n",
      "    df_hero['match_id'] = match_id\n",
      "    return df_team,df_hero\n",
      "\n",
      "def extract_amounts(txt):\n",
      "    t = ''.join(pull_nums.findall(txt))\n",
      "    if t == '':\n",
      "        return 0\n",
      "    else:\n",
      "        return int(t)\n",
      "    \n",
      "def extract_wards(txt):\n",
      "    nums = [extract_amounts(x) for x in txt.split('/')]\n",
      "    return nums\n",
      "    \n",
      "def parse_performace(soup):\n",
      "    match_id = get_match_id(soup)\n",
      "    hero_perf = []\n",
      "    for row in soup.findAll('tr',{'class':faction_find}):\n",
      "        hero = row.find('img')['alt']\n",
      "        tds = row.findAll('td')\n",
      "        values = [extract_amounts(x.text) for x in tds[2::]]\n",
      "        hero_perf = hero_perf + [hero] + values\n",
      "    df = pd.DataFrame(np.reshape(hero_perf,(-1,12)),\n",
      "                      columns = ['hero','tower_kills','barracks_kills',\n",
      "                                 'roshan_kills','tower_dmg','structure_dmg',\n",
      "                                 'aegis_pickup','aegis_use','cheese_pickup',\n",
      "                                 'cheese_use','rune_pickup','rune_use'])\n",
      "    df['match_id'] = match_id\n",
      "    return df\n",
      "\n",
      "def parse_runes(soup):\n",
      "    match_id = get_match_id(soup)\n",
      "    hero_perf = []\n",
      "    for row in soup.findAll('tr',{'class':faction_find}):\n",
      "        hero = row.find('img')['alt']\n",
      "        tds = row.findAll('td')\n",
      "        values = [extract_amounts(x.text) for x in tds[2::]]\n",
      "        hero_perf = hero_perf + [hero] + values\n",
      "    df = pd.DataFrame(np.reshape(hero_perf,(-1,11)),\n",
      "                      columns = ['hero','activated','bottled',\n",
      "                                 'top','bottom','double_damage',\n",
      "                                 'haste','regen','invis',\n",
      "                                 'illusion','bounty'])\n",
      "    df['match_id'] = match_id\n",
      "    return df\n",
      "\n",
      "def parse_vision(soup):\n",
      "    match_id = get_match_id(soup)\n",
      "    hero_perf = []\n",
      "    for row in soup.findAll('tr',{'class':faction_find}):\n",
      "        hero = row.find('img')['alt']\n",
      "        tds = row.findAll('td')\n",
      "        values = [extract_wards(x.text) for x in tds[2:12]]\n",
      "        hero_perf = hero_perf + [hero] + [item for sublist in values for item in sublist] + [duration_to_sec(tds[12])]\n",
      "    df = pd.DataFrame(np.reshape(hero_perf,(-1,17)),\n",
      "                      columns = ['hero','obs_owned','sent_owned',\n",
      "                                 'obs_placed','sent_placed','obs_killed',\n",
      "                                 'sent_killed','dust_owned','dust_used',\n",
      "                                 'dust_hits','dust_acc','smoke_owned',\n",
      "                                 'smoke_used','smoke_hits','gem_owned',\n",
      "                                 'gem_dropped','gem_time_carried'])\n",
      "    df['match_id'] = match_id\n",
      "    return df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 167
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#match_soup = bs4.BeautifulSoup(requests.get('http://www.dotabuff.com/esports/matches').text)\n",
      "#match_id_to_lookup = []\n",
      "#for i in range(1,51):\n",
      "#    match_soup = bs4.BeautifulSoup(requests.get('http://www.dotabuff.com/esports/matches?page=%d' % i).text)\n",
      "#    match_id_to_lookup = match_id_to_lookup + get_match_ids(match_soup)\n",
      "#p.savetxt('D:\\dota2_tournmanet_match_ids.txt', match_id_to_lookup, delimiter=',', fmt = '%d')\n",
      "#match_id_to_lookup = np.loadtxt('D:\\dota2_tournmanet_match_ids.txt', dtype=int)\n",
      "#url = 'http://www.dotabuff.com/matches/%d' % match_id_to_lookup[0]\n",
      "#loc = os.path.join('D:/dota2_matches/','temp_pull.txt')\n",
      "#with open(loc,'wb') as txt_file:\n",
      "#    txt_file.write(requests.get(url).text.encode('UTF-8'))\n",
      "#pull_all_match_pages(match_id_to_lookup[2::])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 154
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path = '/Users/cwharland/Code/dota2_data/data/samples/%s'\n",
      "fName_match = '1154125699_.txt'\n",
      "fName_builds = '1154125699_builds.txt'\n",
      "fName_farm = '1154125699_farm.txt'\n",
      "fName_obj = '1154125699_objectives.txt'\n",
      "fName_runes = '1154125699_runes.txt'\n",
      "fName_vision = '1154125699_vision.txt'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 155
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "soup = bs4.BeautifulSoup(open(path % fName_vision).read())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get_match_details(soup)\n",
      "#parse_game_stats(soup)\n",
      "#parse_ability_builds(soup)\n",
      "#get_picks_and_bans(soup)\n",
      "#parse_diff_xp(soup)\n",
      "#parse_item_sequence(soup)\n",
      "#parse_farm_charts(soup)\n",
      "#parse_performace(soup)\n",
      "#parse_runes(soup)\n",
      "#parse_vision(soup)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 170
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}