{
 "metadata": {
  "name": "",
  "signature": "sha256:796130c2c2d9cb737886e55f6b52a100f186cb653c89ff8999f6b504c9c6b6fc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import bs4\n",
      "import requests\n",
      "import re\n",
      "import json\n",
      "import os\n",
      "#from datetime import timedelta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resp = requests.get('http://www.dotabuff.com/matches/1164772363')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "soup = bs4.BeautifulSoup(resp.text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sides = ['radiant','dire']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rad_sec = soup.find('section',{'class':sides[0]})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ability_col_names = ['Hero'] + ['Level_%d' % x for x in range(1,26)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 192
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stat_fix = re.compile('[k]')\n",
      "dig_fix = re.compile('(\\d)')\n",
      "match_id_parse = re.compile('\\d+')\n",
      "match_href = re.compile('^\\/matches\\/')\n",
      "stat_col_names = ['Team','Hero','Player','Level','Kills','Deaths','Assists','Gold','Last_Hits','Denies','XPM','GPM','Hero_Dmg','Hero_Healed','Tower_Damage','Item_1','Item_2','Item_3','Item_4','Item_5','Item_6']\n",
      "ability_col_names = ['Hero'] + ['Level_%d' % x for x in range(1,26)]\n",
      "details_col_names = ['Tournment','Mode','Region','Duration']\n",
      "sub_pages = ['','builds','kills','farm','objectives','runes','vision','chat','log']\n",
      "\n",
      "def parse_match_section(sec):\n",
      "    title = sec.find('header').text\n",
      "    # Match table\n",
      "    sec_stats = []\n",
      "    for tr in sec.find('table').find_all('tr')[1:6]:\n",
      "        tds = tr.find_all('td')\n",
      "        hero = tds[0].find('img')['title']\n",
      "        player = tds[1].text\n",
      "        stats = [int(''.join(dig_fix.findall(stat_fix.sub('00',tds[i].text)))) for i in range(3,15)]\n",
      "        items = [x['alt'] for x in tds[15].find_all('img')]\n",
      "        if len(items) < 6:\n",
      "            items = items + ['none']*(6-len(items))\n",
      "        parsed_row = [hero] + [player] + stats + items\n",
      "        sec_stats = np.append(sec_stats,np.array(parsed_row))\n",
      "    team_stats = np.array([title]*5).reshape((5,1))\n",
      "    team_stats = np.hstack((team_stats,np.reshape(sec_stats,(5,20))))\n",
      "    return team_stats\n",
      "\n",
      "def parse_game_stats(soup):\n",
      "    match_id = int(match_id_parse.findall(soup.find('div',{'class':'content-header-title'}).text)[0])\n",
      "    teams = np.array(['radiant']*5 + ['dire']*5)\n",
      "    team_stats = []\n",
      "    for side in sides:\n",
      "        sec = soup.find('section',{'class':side})\n",
      "        team_stats = np.append(team_stats, parse_match_section(sec))\n",
      "    team_stats = np.reshape(team_stats, (10,21))\n",
      "    df = pd.DataFrame(team_stats, columns = stat_col_names)\n",
      "    df['Side'] = teams\n",
      "    df['match_id'] = match_id\n",
      "    return df\n",
      "\n",
      "def parse_diff_xp(soup):\n",
      "    match_id = int(match_id_parse.findall(soup.find('div',{'class':'content-header-title'}).text)[0])\n",
      "    plot_json = json.loads(soup.find('div',{'data-flot':'chart-value-minute'})['data-json'])\n",
      "    df = pd.DataFrame(plot_json[1]['data'], columns = ['time','diff_xp'])\n",
      "    df['match_id'] = match_id\n",
      "    return df\n",
      "\n",
      "def parse_ability_builds(soup):\n",
      "    match_id = int(match_id_parse.findall(soup.find('div',{'class':'content-header-title'}).text)[0])\n",
      "    ability_arr = []\n",
      "    for team in soup.find_all('article',{'class':'ability-builds'}):\n",
      "        for tr in team.find_all('tr')[1::]:\n",
      "            skill_arr = []\n",
      "            for td in tr.find_all('td'):\n",
      "                if td.find('img') is not None:\n",
      "                    skill_arr.append(td.find('img')['alt'])\n",
      "                else:\n",
      "                    skill_arr.append('none')\n",
      "            ability_arr = ability_arr + skill_arr\n",
      "    ability_arr = np.reshape(ability_arr, (10,26))\n",
      "    df = pd.DataFrame(ability_arr, columns = ability_col_names)\n",
      "    df['match_id'] = match_id\n",
      "    return df\n",
      "\n",
      "def get_match_details(soup):\n",
      "    match_id = int(match_id_parse.findall(soup.find('div',{'class':'content-header-title'}).text)[0])\n",
      "    dds = soup.find('div',{'id':'content-header-secondary'}).find_all('dd')\n",
      "    details = [x.text for x in dds[:-1]]\n",
      "    details[-1] = duration_to_sec(details[-1])\n",
      "    time_stamp = pd.to_datetime(dds[-1].find('time')['datetime'])\n",
      "    match_details = np.append(match_id, details)\n",
      "    match_details = np.append(match_details, time_stamp)\n",
      "    match_details[0] = int(match_details[0])\n",
      "    return match_details\n",
      "    \n",
      "def duration_to_sec(dur_str):\n",
      "    vals = [int(x) for x in dur_str.split(':')]\n",
      "    return vals[0]*60 + vals[1]\n",
      "\n",
      "def get_match_ids(soup):\n",
      "    return [int(x.text) for x in match_soup.find_all('a', href = match_href, text = match_id_parse)]\n",
      "\n",
      "def pull_all_match_pages(ids):\n",
      "    for m_id in ids:\n",
      "        base_url = 'http://www.dotabuff.com/matches/%d' % m_id\n",
      "        for page in sub_pages:\n",
      "            fetch_url = base_url + '/' + page\n",
      "            fName = os.path.join('D:/dota2_matches/%s/' % page, '%d_%s.txt' % (m_id,page))\n",
      "            with open(fName, 'wb') as txt_file:\n",
      "                txt_file.write(requests.get(fetch_url).text.encode('UTF-8'))            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "match_soup = bs4.BeautifulSoup(requests.get('http://www.dotabuff.com/esports/matches').text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 320
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#match_id_to_lookup = []\n",
      "#for i in range(1,51):\n",
      "#    match_soup = bs4.BeautifulSoup(requests.get('http://www.dotabuff.com/esports/matches?page=%d' % i).text)\n",
      "#    match_id_to_lookup = match_id_to_lookup + get_match_ids(match_soup)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 340
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#p.savetxt('D:\\dota2_tournmanet_match_ids.txt', match_id_to_lookup, delimiter=',', fmt = '%d')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 345
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "match_id_to_lookup = np.loadtxt('D:\\dota2_tournmanet_match_ids.txt', dtype=int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "url = 'http://www.dotabuff.com/matches/%d' % match_id_to_lookup[0]\n",
      "loc = os.path.join('D:/dota2_matches/','temp_pull.txt')\n",
      "with open(loc,'wb') as txt_file:\n",
      "    txt_file.write(requests.get(url).text.encode('UTF-8'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 368
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "os.path.join('D:/%s/' % 'runes', '%d_%s.txt' % (match_id_to_lookup[0],'runes'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 365,
       "text": [
        "'D:/runes/1165586525_runes.txt'"
       ]
      }
     ],
     "prompt_number": 365
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pull_all_match_pages(match_id_to_lookup[2::])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}