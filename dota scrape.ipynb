{
 "metadata": {
  "name": "",
  "signature": "sha256:3c5d188ad4f5615451c0cba1a63ba5904cad6d95e1d8509b0d38d99dc9a71092"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import bs4\n",
      "import requests\n",
      "import re\n",
      "import json\n",
      "import os\n",
      "#from datetime import timedelta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resp = requests.get('http://www.dotabuff.com/matches/1154125699')\n",
      "soup = bs4.BeautifulSoup(resp.text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stat_fix = re.compile('[k]')\n",
      "dig_fix = re.compile('(\\d)')\n",
      "match_id_parse = re.compile('\\d+')\n",
      "match_href = re.compile('^\\/matches\\/')\n",
      "pick_ban = re.compile('(ban|pick)')\n",
      "\n",
      "stat_col_names = ['Team','Hero','Player','Level','Kills','Deaths','Assists','Gold','Last_Hits','Denies','XPM','GPM','Hero_Dmg','Hero_Healed','Tower_Damage','Item_1','Item_2','Item_3','Item_4','Item_5','Item_6']\n",
      "ability_col_names = ['Hero'] + ['Level_%d' % x for x in range(1,26)]\n",
      "details_col_names = ['Tournment','Mode','Region','Duration']\n",
      "sub_pages = ['','builds','kills','farm','objectives','runes','vision','chat','log']\n",
      "sides = ['radiant','dire']\n",
      "\n",
      "def parse_match_section(sec):\n",
      "    title = sec.find('header').text\n",
      "    # Match table\n",
      "    sec_stats = []\n",
      "    for tr in sec.find('table').find_all('tr')[1:6]:\n",
      "        tds = tr.find_all('td')\n",
      "        hero = tds[0].find('img')['title']\n",
      "        player = tds[1].text\n",
      "        stats = [int(''.join(dig_fix.findall(stat_fix.sub('00',tds[i].text)))) for i in range(3,15)]\n",
      "        items = [x['alt'] for x in tds[15].find_all('img')]\n",
      "        if len(items) < 6:\n",
      "            items = items + ['none']*(6-len(items))\n",
      "        parsed_row = [hero] + [player] + stats + items\n",
      "        sec_stats = np.append(sec_stats,np.array(parsed_row))\n",
      "    team_stats = np.array([title]*5).reshape((5,1))\n",
      "    team_stats = np.hstack((team_stats,np.reshape(sec_stats,(5,20))))\n",
      "    return team_stats\n",
      "\n",
      "def parse_game_stats(soup):\n",
      "    match_id = int(match_id_parse.findall(soup.find('div',{'class':'content-header-title'}).text)[0])\n",
      "    teams = np.array(['radiant']*5 + ['dire']*5)\n",
      "    team_stats = []\n",
      "    for side in sides:\n",
      "        sec = soup.find('section',{'class':side})\n",
      "        team_stats = np.append(team_stats, parse_match_section(sec))\n",
      "    team_stats = np.reshape(team_stats, (10,21))\n",
      "    df = pd.DataFrame(team_stats, columns = stat_col_names)\n",
      "    df['Side'] = teams\n",
      "    df['match_id'] = match_id\n",
      "    return df\n",
      "\n",
      "def parse_diff_xp(soup):\n",
      "    match_id = int(match_id_parse.findall(soup.find('div',{'class':'content-header-title'}).text)[0])\n",
      "    plot_json = json.loads(soup.find('div',{'data-flot':'chart-value-minute'})['data-json'])\n",
      "    df = pd.DataFrame(plot_json[1]['data'], columns = ['time','diff_xp'])\n",
      "    df['match_id'] = match_id\n",
      "    return df\n",
      "\n",
      "def parse_ability_builds(soup):\n",
      "    match_id = int(match_id_parse.findall(soup.find('div',{'class':'content-header-title'}).text)[0])\n",
      "    ability_arr = []\n",
      "    for team in soup.find_all('article',{'class':'ability-builds'}):\n",
      "        for tr in team.find_all('tr')[1::]:\n",
      "            skill_arr = []\n",
      "            for td in tr.find_all('td'):\n",
      "                if td.find('img') is not None:\n",
      "                    skill_arr.append(td.find('img')['alt'])\n",
      "                else:\n",
      "                    skill_arr.append('none')\n",
      "            ability_arr = ability_arr + skill_arr\n",
      "    ability_arr = np.reshape(ability_arr, (10,26))\n",
      "    df = pd.DataFrame(ability_arr, columns = ability_col_names)\n",
      "    df['match_id'] = match_id\n",
      "    return df\n",
      "\n",
      "def get_match_details(soup):\n",
      "    match_id = int(match_id_parse.findall(soup.find('div',{'class':'content-header-title'}).text)[0])\n",
      "    dds = soup.find('div',{'id':'content-header-secondary'}).find_all('dd')\n",
      "    details = [x.text for x in dds[:-1]]\n",
      "    details[-1] = duration_to_sec(details[-1])\n",
      "    time_stamp = pd.to_datetime(dds[-1].find('time')['datetime'])\n",
      "    match_details = np.append(match_id, details)\n",
      "    match_details = np.append(match_details, time_stamp)\n",
      "    match_details[0] = int(match_details[0])\n",
      "    return match_details\n",
      "    \n",
      "def duration_to_sec(dur_str):\n",
      "    vals = [int(x) for x in dur_str.split(':')]\n",
      "    if vals[0] < 0:\n",
      "        return vals[0]*60 - vals[1]\n",
      "    else:\n",
      "        return vals[0]*60 + vals[1]\n",
      "\n",
      "def get_match_ids(soup):\n",
      "    return [int(x.text) for x in match_soup.find_all('a', href = match_href, text = match_id_parse)]\n",
      "\n",
      "def pull_all_match_pages(ids):\n",
      "    for m_id in ids:\n",
      "        base_url = 'http://www.dotabuff.com/matches/%d' % m_id\n",
      "        for page in sub_pages:\n",
      "            fetch_url = base_url + '/' + page\n",
      "            fName = os.path.join('D:/dota2_matches/%s/' % page, '%d_%s.txt' % (m_id,page))\n",
      "            with open(fName, 'wb') as txt_file:\n",
      "                txt_file.write(requests.get(fetch_url).text.encode('UTF-8'))   \n",
      "                \n",
      "def get_picks_and_bans(soup):\n",
      "    match_id = int(match_id_parse.findall(soup.find('div',{'class':'content-header-title'}).text)[0])\n",
      "    pb = soup.findAll('div',{'class':pick_ban})\n",
      "    pb_phase = []\n",
      "    for hero in pb[1::]:\n",
      "        sel = hero['class'][0]\n",
      "        name = hero.find('img')['alt']\n",
      "        seq = int(hero.find('div',{'class':'seq'}).text)\n",
      "        pb_phase = pb_phase + [seq,sel,name]\n",
      "    df = pd.DataFrame(np.reshape(pb_phase, (-1,3)), columns = ['sequence', 'action','hero'])\n",
      "    df = df[df.action != 'picks-inline']\n",
      "    df['sequence'] = df.sequence.astype(int)\n",
      "    df['match_id'] = match_id\n",
      "    return df.sort('sequence').reset_index(drop = True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 202
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#match_soup = bs4.BeautifulSoup(requests.get('http://www.dotabuff.com/esports/matches').text)\n",
      "#match_id_to_lookup = []\n",
      "#for i in range(1,51):\n",
      "#    match_soup = bs4.BeautifulSoup(requests.get('http://www.dotabuff.com/esports/matches?page=%d' % i).text)\n",
      "#    match_id_to_lookup = match_id_to_lookup + get_match_ids(match_soup)\n",
      "#p.savetxt('D:\\dota2_tournmanet_match_ids.txt', match_id_to_lookup, delimiter=',', fmt = '%d')\n",
      "#match_id_to_lookup = np.loadtxt('D:\\dota2_tournmanet_match_ids.txt', dtype=int)\n",
      "#url = 'http://www.dotabuff.com/matches/%d' % match_id_to_lookup[0]\n",
      "#loc = os.path.join('D:/dota2_matches/','temp_pull.txt')\n",
      "#with open(loc,'wb') as txt_file:\n",
      "#    txt_file.write(requests.get(url).text.encode('UTF-8'))\n",
      "#pull_all_match_pages(match_id_to_lookup[2::])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path = '/Users/cwharland/Code/dota2_data/data/samples/%s'\n",
      "fName_match = '1154125699_.txt'\n",
      "fName_builds = '1154125699_builds.txt'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 186
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "soup = bs4.BeautifulSoup(open(path % fName_builds).read())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 187
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get_match_details(soup)\n",
      "#parse_game_stats(soup)\n",
      "#parse_ability_builds(soup)\n",
      "#get_picks_and_bans(soup)\n",
      "#parse_diff_xp(soup)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 188
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "build = soup.findAll('section',{'class':'performance-artifact'})[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 191
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hero_finder = re.compile('\\/heroes\\/\\w+')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 208
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "build.find('a', {'href':hero_finder}).find('img')['alt']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 212,
       "text": [
        "u'Silencer'"
       ]
      }
     ],
     "prompt_number": 212
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "buy = build.find('div',{'class':'segment expanded'})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 198
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[x['alt'] for x in buy.findAll('img')]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 206,
       "text": [
        "[u'Sentry Ward', u'Observer Ward', u'Tango', u'Clarity']"
       ]
      }
     ],
     "prompt_number": 206
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def parse_item_sequence(soup):\n",
      "    match_id = int(match_id_parse.findall(soup.find('div',{'class':'content-header-title'}).text)[0])\n",
      "    players = soup.findAll('section',{'class':'performance-artifact'})\n",
      "    for player in players:\n",
      "        hero = player.find('a', {'href':hero_finder}).find('img')['alt']\n",
      "        for buy in player.findAll('div',{'class':'segment expanded'}):\n",
      "            time_stamp = duration_to_sec(buy.find('div',{'class':'time'}).text)\n",
      "            items = [x['alt'] for x in buy.findAll('img')]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}